{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import neurolab as nl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise # 1:\n",
    "Single Layer Feed Forward to Recognize Sum Pattern (20 marks)\n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. **Create the training data (input):**\n",
    "   - Use `numpy` to generate two sets of 10 numbers drawn from a uniform distribution. Set the numbers to fall between -0.6 and +0.6.\n",
    "   - Save these numbers in a 10 by 2 `ndarray`, where each set is considered a feature.\n",
    "   - Name the `ndarray` as `input_firstname`, where `firstname` is your first name.\n",
    "\n",
    "2. **Create the target data (output):**\n",
    "   - The target output is the sum of the two random values for each instance of the input data.\n",
    "   - For example:\n",
    "\n",
    "     | Input Data   | Output Data |\n",
    "     |--------------|-------------|\n",
    "     | 0.1   0.45   | 0.55        |\n",
    "     | 0.035 0.21   | 0.245       |\n",
    "     | ...   ...    | ...         |\n",
    "\n",
    "     i.e., \\( y = x_1 + x_2 \\)\n",
    "\n",
    "   - Store the output in a `ndarray` of size 10 by 1.\n",
    "   - Name this `ndarray` as `output_firstname`, where `firstname` is your first name.\n",
    "\n",
    "3. **Set the seed:** `seed = 1`\n",
    "\n",
    "4. **Using `neurolab`, create a simple neural network:**\n",
    "   - The network should have:\n",
    "     - Two inputs\n",
    "     - Six neurons in a single layer\n",
    "     - One output\n",
    "\n",
    "5. **Train the network** using the input and output data created in points 1 and 2.\n",
    "   - Set the following parameters:\n",
    "     - `show=15`\n",
    "     - `goal=0.00001`\n",
    "\n",
    "6. **Train the network** using the 10 data points.\n",
    "\n",
    "7. **Test / Simulate the network:**\n",
    "   - Pass the following test values: 0.1 and 0.2\n",
    "   - Record the result under **result #1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the training data(input):\n",
    "# 2. Generating the training data (input)\n",
    "input_beta = np.random.uniform(-0.6, 0.6, (10, 2))\n",
    "print(\"Generated Input (input_beta):\\n\", input_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Creating the target data (output)\n",
    "output_beta = np.sum(input_beta, axis=1).reshape(10, 1)\n",
    "print(\"Generated Output (output_beta):\\n\", output_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Setting seed to 1\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Setting up the neural network\n",
    "input_range = [[-0.6, 0.6], [-0.6, 0.6]]\n",
    "net = nl.net.newff(input_range, [6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Setting training parameters and 7. Training the network using the 10 data points.\n",
    "net.trainf = nl.train.train_gd  # Set training function to gradient descent\n",
    "error = net.train(input_beta, output_beta, show=15, goal=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Testing the network\n",
    "test_input = np.array([[0.1, 0.2]])\n",
    "result_1 = net.sim(test_input)\n",
    "print(\"Result for test input [0.1, 0.2]:\", result_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise # 2:\n",
    "Multi-Layer Feed Forward to Recognize Sum Pattern (20 marks)\n",
    "\n",
    "1. **Repeat steps 1-8 from Exercise #1** except for step #5, where you will:\n",
    "   - Create a two-layer feed-forward network, i.e., two hidden layers:\n",
    "     - The first hidden layer with 5 neurons\n",
    "     - The second hidden layer with 3 neurons\n",
    "   - Set the following parameters:\n",
    "     - `epochs=1000`\n",
    "     - `show=100`\n",
    "     - `goal=0.00001`\n",
    "\n",
    "2. **Record the result** under **result #2**.\n",
    "\n",
    "3. **Set the training algorithm** to Gradient Descent Backpropagation.\n",
    "\n",
    "4. **Written Response**:\n",
    "   - Compare **result #1** to **result #2** and to the actual result.\n",
    "   - Explain your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the training data(input):\n",
    "# 2. Generating the training data (input)\n",
    "input_beta = np.random.uniform(-0.6, 0.6, (10, 2))\n",
    "print(\"Generated Input (input_beta):\\n\", input_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Creating the target data (output)\n",
    "output_beta = np.sum(input_beta, axis=1).reshape(10, 1)\n",
    "print(\"Generated Output (output_beta):\\n\", output_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Setting seed to 1\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Setting up the neural network: 5 neurons in the first layer, 3 in the second, 1 output\n",
    "input_range = [[-0.6, 0.6], [-0.6, 0.6]]\n",
    "net = nl.net.newff(input_range, [5, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Setting training parameters: epochs=1000, show=100, goal=0.00001\n",
    "# 7. Training the network using the 10 data points.\n",
    "net.trainf = nl.train.train_gd  # train_gd provides gradient descent with backpropagation\n",
    "error = net.train(input_beta, output_beta, epochs=1000, show=100, goal=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Testing the network\n",
    "test_input = np.array([[0.1, 0.2]])\n",
    "result_2 = net.sim(test_input)\n",
    "print(\"Result for test input [0.1, 0.2]:\", result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise # 3:\n",
    "Single-Layer Feed Forward to Recognize Sum Pattern with More Training Data (20 marks)\n",
    "\n",
    "1. **Repeat steps 1-3 from Exercise #1**:\n",
    "   - Generate 100 random instances this time instead of 10.\n",
    "\n",
    "2. **Repeat steps 4-8 from Exercise #1**.\n",
    "\n",
    "3. **Record the result** as **result #3**.\n",
    "\n",
    "4. **Written Response**:\n",
    "   - Compare **result #1** to **result #3** and to the actual result.\n",
    "   - Explain your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Step 1-3: Generate input and output data with 100 instances\n",
    "input_beta_large = np.random.uniform(-0.6, 0.6, (100, 2))\n",
    "output_beta_large = np.sum(input_beta_large, axis=1).reshape(100, 1)\n",
    "\n",
    "print(\"Generated Input (input_beta_large):\\n\", input_beta_large)\n",
    "print(\"Generated Output (output_beta_large):\\n\", output_beta_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Set up the neural network\n",
    "input_range = [[-0.6, 0.6], [-0.6, 0.6]]\n",
    "net_large = nl.net.newff(input_range, [6, 1])\n",
    "\n",
    "# Step 6: Set training parameters and train the network with the larger dataset\n",
    "net_large.trainf = nl.train.train_gd  # Set training function to gradient descent\n",
    "error_large = net_large.train(input_beta_large, output_beta_large, show=15, goal=0.00001)\n",
    "\n",
    "# Step 8: Test the network with the same input [0.1, 0.2]\n",
    "test_input_large = np.array([[0.1, 0.2]])\n",
    "result_3 = net_large.sim(test_input_large)\n",
    "print(\"Result for test input [0.1, 0.2] with 100 training instances:\", result_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Result #1 and Result #3:\n",
    "\n",
    "# Accuracy:\n",
    "The prediction for [0.1, 0.2] improved when training with 100 instances, this shows that a larger dataset can help the model generalize better.\n",
    "\n",
    "# Error Trend: \n",
    "With the larger dataset, the model took longer to reach the goal, and the final error remained higher than with the 10-instance dataset. \n",
    "This may also indicate that the model is struggling with the increased complexity, possibly due to limitations in the network architecture (only one hidden layer with 6 neurons).\n",
    "\n",
    "# Output Stability:\n",
    "Training with more instances appears to have stabilized the network output, making it less sensitive to variations and better able to approximate the target sum function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise # 4:\n",
    "Multi-Layer Feed Forward to Recognize Sum Pattern with More Training Data (20 marks)\n",
    "\n",
    "1. **Repeat step #1 in Exercise #3**:\n",
    "   - Generate 100 random samples as the training data.\n",
    "\n",
    "2. **Create a two-layer feed-forward network**:\n",
    "   - Two hidden layers:\n",
    "     - The first hidden layer with 5 neurons\n",
    "     - The second hidden layer with 3 neurons\n",
    "   - Set the following parameters:\n",
    "     - `epochs=1000`\n",
    "     - `show=100`\n",
    "     - `goal=0.00001`\n",
    "\n",
    "3. **Set the training algorithm** to Gradient Descent Backpropagation.\n",
    "\n",
    "4. **Train the network** using the 100 data points.\n",
    "\n",
    "5. **Plot the error vs. training size** graph.\n",
    "\n",
    "6. **Test / Simulate the network**:\n",
    "   - Pass the following test values: 0.1 and 0.2.\n",
    "   - Record the result under **result #4**.\n",
    "\n",
    "7. **Written Response**:\n",
    "   - Compare **result #3** to **result #4** and to the actual result.\n",
    "   - Explain your findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise # 5:\n",
    "Three-Input Multi-Layer Feed Forward to Recognize Sum Pattern with More Training Data (20 marks)\n",
    "\n",
    "1. **Repeat Exercise #1**:\n",
    "   - Instead of two inputs, generate **three inputs** for the training data.\n",
    "\n",
    "2. **Test / Simulate the Network**:\n",
    "   - Use the test sample `[0.2, 0.1, 0.2]`.\n",
    "   - Record the results as **result #5**.\n",
    "\n",
    "3. **Repeat Exercise #4**:\n",
    "   - Modify it to have **three inputs** instead of two.\n",
    "\n",
    "4. **Test / Simulate the Network**:\n",
    "   - Use the test sample `[0.2, 0.1, 0.2]`.\n",
    "   - Record the results as **result #6**.\n",
    "\n",
    "5. **Written Response**:\n",
    "   - Compare **result #5** to **result #6** and to the actual result.\n",
    "   - Explain your findings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
